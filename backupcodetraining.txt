import pandas as pd
import random
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from transformers import BertTokenizerFast, BertForTokenClassification, Trainer, TrainingArguments
import torch
from torch.utils.data import Dataset
import numpy as np
import matplotlib.pyplot as plt

# Define the chunk size
chunk_size = 100  # Adjust based on your memory capacity
chunks = []

# Define the path to your CSV file
data_path = r"D:\project\Food recommendation\Backend\actual dataset\recipes_data.csv"

# Read the CSV file in chunks
for chunk in pd.read_csv(data_path, chunksize=chunk_size):
    chunks.append(chunk)

# Concatenate the chunks into a single DataFrame
data = pd.concat(chunks, ignore_index=True)

# Sample from the dataset
sampled_data = data.sample(n=1000, random_state=42).reset_index(drop=True)# Initialize lists to hold sentences and labels
sentences = []
labels = []

# Iterate over each row in the sampled DataFrame
for index, row in sampled_data.iterrows():
    # Extract the ingredients from the NER column
    ingredients_row = row['NER']  # Adjust based on your actual column name
    ingredients = eval(ingredients_row)  # Convert string representation of list to actual list

    # Generate sentences for each ingredient
    for ingredient in ingredients:
        for _ in range(2):  # Generate 2 sentences for each ingredient
            # Create a sentence
            sentence = f"I want to have {ingredient}."
            sentences.append(sentence)

            # Create labels
            words = sentence.split()
            label = ["O"] * len(words)  # Default label is 'O' (Outside)

            # Create labels for the ingredient
            ingredient_words = ingredient.split()
            if len(ingredient_words) > 0:
                label[3] = "B-INGREDIENT"  # Beginning of the ingredient
                for i in range(1, len(ingredient_words)):
                    if 3 + i < len(label):  # Avoid index out of range
                        label[3 + i] = "I-INGREDIENT"  # Inside the ingredient

            labels.append(label)

# Check the generated sentences and labels
print("Generated Sentences and Labels:")
for sentence, label in zip(sentences[:20], labels[:20]):  # Display first 20 for brevity
    print(sentence, label)

class NERDataset(Dataset):
    def __init__(self, sentences, labels):
        self.tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')

        # Check if sentences is a list of strings
        if not isinstance(sentences, list) or not all(isinstance(s, str) for s in sentences):
            raise ValueError("Sentences should be a list of strings.")

        # Tokenize sentences
        self.encodings = self.tokenizer(sentences, truncation=True, padding=True, is_split_into_words=False, return_tensors='pt')

        # Create a new label list that matches the tokenization
        self.labels = []
        for i, label in enumerate(labels):
            encoded_label = [-100] * len(self.encodings['input_ids'][i])  # Default label for padding

            # Get word ids for the current sentence
            word_ids = self.encodings.word_ids(batch_index=i)  # This should correspond to the tokens in that sentence
            if word_ids is None:
                print(f"Warning: No word_ids for sentence index {i}")
                continue

            for j, word_id in enumerate(word_ids):
                if word_id is None:
                    continue  # Ignore special tokens
                if word_id < len(label):  # Ensure we do not access out of range
                    if label[word_id] != "O":
                        encoded_label[j] = 1 if label[word_id] == "B-INGREDIENT" else 0  # Binary label

            self.labels.append(encoded_label)

    def __getitem__(self, idx):
        item = {key: val[idx] for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

# Split the data into training and testing sets
train_sentences, test_sentences, train_labels, test_labels = train_test_split(sentences, labels, test_size=0.2, random_state=42)

# Reduce the number of training and testing sentences by half
train_sentences = train_sentences[:len(train_sentences)//8]
train_labels = train_labels[:len(train_labels)//8]
test_sentences = test_sentences[:len(test_sentences)//8]
test_labels = test_labels[:len(test_labels)//8]

# Print the number of training and testing sentences and labels
print(f"Number of training sentences: {len(train_sentences)}, Number of training labels: {len(train_labels)}")
print(f"Number of testing sentences: {len(test_sentences)}, Number of testing labels: {len(test_labels)}")

# Before creating the Dataset objects, print the structure of the sentences
print(f"Number of training sentences: {len(train_sentences)}")
print("First few training sentences:")
for sentence in train_sentences[:20]:  # Print the first 20 sentences
    print(sentence)

# Create Dataset objects
train_dataset = NERDataset(train_sentences, train_labels)
test_dataset = NERDataset(test_sentences, test_labels)

# Debugging: Check tokenization and label alignment
for i in range(5):  # Check a few examples
    # Get the input IDs for the ith example
    input_ids = train_dataset.encodings['input_ids'][i]
    labels = train_dataset.labels[i]

    # Convert input IDs to tokens
    tokens = train_dataset.tokenizer.convert_ids_to_tokens(input_ids.tolist())

    print(f"Sentence {i}:")
    print("Tokens:", tokens)
    print("Labels:", labels)
    print("\n")

# Load BERT model for token classification
model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=2)  # Adjust num_labels based on your data

# Training arguments
training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=1.5,  # Reduced epochs by half
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    warmup_steps=250,  # Reduced warmup steps
    weight_decay=0.01,
    logging_dir='./logs',
    logging_steps=10,
)

# Evaluation function
def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)

    # Flatten the labels and preds arrays
    true_labels = np.concatenate([label[label != -100] for label in labels])
    true_preds = np.concatenate([pred[label != -100] for pred, label in zip(preds, labels)])

    accuracy = accuracy_score(true_labels, true_preds)
    precision = precision_score(true_labels, true_preds, average='macro')
    recall = recall_score(true_labels, true_preds, average='macro')
    f1 = f1_score(true_labels, true_preds, average='macro')

    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
    }

# Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
    compute_metrics=compute_metrics
)
# Train the model
trainer.train()

# Evaluate the model
eval_results = trainer.evaluate()

# Print evaluation results
print(f"Accuracy: {eval_results['eval_accuracy']}")
print(f"Precision: {eval_results['eval_precision']}")
print(f"Recall: {eval_results['eval_recall']}")
print(f"F1 Score: {eval_results['eval_f1']}")

# Visualization
metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']
values = [eval_results['eval_accuracy'], eval_results['eval_precision'], eval_results['eval_recall'], eval_results['eval_f1']]

plt.figure(figsize=(10, 6))
plt.bar(metrics, values, color=['blue', 'green', 'red', 'purple'])
plt.ylabel('Scores')
plt.title('Evaluation Metrics')
plt.ylim(0, 2)
plt.show()

# Save the model
model.save_pretrained('D:\project\Food recommendation\Model\Saved model')